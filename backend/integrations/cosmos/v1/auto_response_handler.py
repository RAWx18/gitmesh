"""
Auto Response Handler for Cosmos Integration
Eliminates all user prompts by providing automatic responses based on context
"""
import re
import logging
from typing import Dict, Any, Optional, List, Tuple
from dataclasses import dataclass
from enum import Enum
import structlog

logger = structlog.get_logger(__name__)

class PromptType(Enum):
    """Types of prompts that Cosmos might generate"""
    REPOSITORY_SELECTION = "repository_selection"
    CONFIRMATION = "confirmation"
    FILE_SELECTION = "file_selection"
    TOKEN_REQUEST = "token_request"
    DELETE_CONFIRMATION = "delete_confirmation"
    FETCH_NEW = "fetch_new"
    GENERAL_INPUT = "general_input"
    YES_NO = "yes_no"
    NUMBER_SELECTION = "number_selection"
    UNKNOWN = "unknown"

@dataclass
class PromptPattern:
    """Pattern matching configuration for different prompt types"""
    pattern: str
    prompt_type: PromptType
    default_response: str
    context_aware: bool = False
    description: str = ""

@dataclass
class AutoResponse:
    """Response generated by the auto-response handler"""
    response: str
    prompt_type: PromptType
    confidence: float
    reasoning: str
    original_prompt: str

class AutoResponseHandler:
    """
    Handles automatic responses to Cosmos prompts to eliminate user interaction.
    
    This class intercepts prompts from Cosmos and provides context-aware automatic
    responses based on pattern matching and current repository context.
    """
    
    def __init__(self, repository_context: Dict[str, Any] = None):
        """
        Initialize the auto-response handler.
        
        Args:
            repository_context: Current repository context including URL, branch, etc.
        """
        self.repository_context = repository_context or {}
        self.response_log = []  # Track all automated responses for debugging
        self.prompt_patterns = self._initialize_prompt_patterns()
        
        logger.info("AutoResponseHandler initialized", 
                   repository_url=self.repository_context.get("repository_url"))
    
    def _initialize_prompt_patterns(self) -> List[PromptPattern]:
        """Initialize the prompt patterns for different types of Cosmos prompts"""
        return [
            # Delete confirmation patterns (most specific first)
            PromptPattern(
                pattern=r"delete all files.*\(y/n\)",
                prompt_type=PromptType.DELETE_CONFIRMATION,
                default_response="n",
                description="Delete all files confirmation - default to no"
            ),
            PromptPattern(
                pattern=r"delete.*files.*\?",
                prompt_type=PromptType.DELETE_CONFIRMATION,
                default_response="n",
                description="Delete files confirmation - default to no"
            ),
            PromptPattern(
                pattern=r"delete all",
                prompt_type=PromptType.DELETE_CONFIRMATION,
                default_response="n",
                description="Delete all confirmation - default to no"
            ),
            PromptPattern(
                pattern=r"delete.*\(y/n\)",
                prompt_type=PromptType.DELETE_CONFIRMATION,
                default_response="n",
                description="Delete confirmation - default to no"
            ),
            PromptPattern(
                pattern=r"remove.*\(y/n\)",
                prompt_type=PromptType.DELETE_CONFIRMATION,
                default_response="n",
                description="Remove confirmation - default to no"
            ),
            
            # Repository selection patterns
            PromptPattern(
                pattern=r"select repository.*\(1-\d+\)",
                prompt_type=PromptType.REPOSITORY_SELECTION,
                default_response="1",
                context_aware=True,
                description="Repository selection from cached list"
            ),
            PromptPattern(
                pattern=r"repository.*\(1-\d+\).*or.*new.*delete",
                prompt_type=PromptType.REPOSITORY_SELECTION,
                default_response="1",
                context_aware=True,
                description="Repository selection with new/delete options"
            ),
            PromptPattern(
                pattern=r"enter repository url",
                prompt_type=PromptType.REPOSITORY_SELECTION,
                default_response="",
                context_aware=True,
                description="Repository URL input request"
            ),
            
            # Confirmation patterns
            PromptPattern(
                pattern=r"are you sure.*\(y/n\)",
                prompt_type=PromptType.CONFIRMATION,
                default_response="y",
                description="General confirmation prompt"
            ),
            PromptPattern(
                pattern=r"continue.*\(y/n\)",
                prompt_type=PromptType.CONFIRMATION,
                default_response="y",
                description="Continue confirmation"
            ),
            PromptPattern(
                pattern=r"proceed.*\(y/n\)",
                prompt_type=PromptType.CONFIRMATION,
                default_response="y",
                description="Proceed confirmation"
            ),
            
            # Token request patterns
            PromptPattern(
                pattern=r"github token",
                prompt_type=PromptType.TOKEN_REQUEST,
                default_response="",
                description="GitHub token request - skip"
            ),
            PromptPattern(
                pattern=r"api key",
                prompt_type=PromptType.TOKEN_REQUEST,
                default_response="",
                description="API key request - skip"
            ),
            
            # Fetch new patterns
            PromptPattern(
                pattern=r"fetch new.*\(y/n\)",
                prompt_type=PromptType.FETCH_NEW,
                default_response="n",
                description="Fetch new data - default to no"
            ),
            PromptPattern(
                pattern=r"update.*\(y/n\)",
                prompt_type=PromptType.FETCH_NEW,
                default_response="n",
                description="Update data - default to no"
            ),
            
            # Number selection patterns
            PromptPattern(
                pattern=r"select.*\(1-\d+\)",
                prompt_type=PromptType.NUMBER_SELECTION,
                default_response="1",
                description="Number selection - default to first option"
            ),
            PromptPattern(
                pattern=r"select option.*\(1-\d+\)",
                prompt_type=PromptType.NUMBER_SELECTION,
                default_response="1",
                description="Option selection - default to first option"
            ),
            
            # File selection patterns
            PromptPattern(
                pattern=r"select files.*\(1-\d+\)",
                prompt_type=PromptType.FILE_SELECTION,
                default_response="all",
                description="File selection - select all"
            ),
            
            # General yes/no patterns (catch-all)
            PromptPattern(
                pattern=r"\(y/n\)|\(yes/no\)",
                prompt_type=PromptType.YES_NO,
                default_response="y",
                description="General yes/no prompt - default to yes"
            )
        ]
    
    def intercept_prompt(self, prompt: str, context: Dict[str, Any] = None) -> str:
        """
        Intercept a prompt and provide an automatic response.
        
        Args:
            prompt: The prompt text from Cosmos
            context: Additional context for the prompt
            
        Returns:
            Automatic response string
        """
        # Clean and normalize the prompt
        normalized_prompt = prompt.lower().strip()
        
        # Find matching pattern
        auto_response = self._match_prompt_pattern(normalized_prompt, prompt)
        
        # Log the automated response
        self._log_response(auto_response)
        
        # Apply context-aware logic if needed
        if auto_response.prompt_type == PromptType.REPOSITORY_SELECTION:
            final_response = self._apply_context_logic(auto_response, context)
        else:
            final_response = auto_response.response
        
        logger.info("Auto-response generated",
                   prompt=prompt[:100],
                   response=final_response,
                   prompt_type=auto_response.prompt_type.value,
                   confidence=auto_response.confidence)
        
        return final_response
    
    def _match_prompt_pattern(self, normalized_prompt: str, original_prompt: str) -> AutoResponse:
        """
        Match the prompt against known patterns and generate response.
        
        Args:
            normalized_prompt: Lowercase, stripped prompt text
            original_prompt: Original prompt text
            
        Returns:
            AutoResponse object with response details
        """
        best_match = None
        highest_confidence = 0.0
        
        for pattern_config in self.prompt_patterns:
            if re.search(pattern_config.pattern, normalized_prompt, re.IGNORECASE):
                # Calculate confidence based on pattern specificity and length
                pattern_length = len(pattern_config.pattern)
                prompt_length = max(len(normalized_prompt), 1)
                
                # Give higher confidence to longer, more specific patterns
                confidence = (pattern_length / prompt_length) * 0.7 + (pattern_length / 100) * 0.3
                confidence = min(confidence, 1.0)  # Cap at 1.0
                
                if confidence > highest_confidence:
                    highest_confidence = confidence
                    best_match = pattern_config
        
        if best_match:
            return AutoResponse(
                response=best_match.default_response,
                prompt_type=best_match.prompt_type,
                confidence=highest_confidence,
                reasoning=best_match.description,
                original_prompt=original_prompt
            )
        else:
            # Unknown prompt type - provide safe default
            return AutoResponse(
                response="",
                prompt_type=PromptType.UNKNOWN,
                confidence=0.1,
                reasoning="Unknown prompt pattern - using empty response",
                original_prompt=original_prompt
            )
    
    def _apply_context_logic(self, auto_response: AutoResponse, context: Dict[str, Any] = None) -> str:
        """
        Apply context-aware logic to modify the response based on current context.
        
        Args:
            auto_response: The initial auto response
            context: Additional context for decision making
            
        Returns:
            Final response string
        """
        if auto_response.prompt_type == PromptType.REPOSITORY_SELECTION:
            return self._handle_repository_selection(auto_response, context)
        
        # For other context-aware prompts, return default response
        return auto_response.response
    
    def _handle_repository_selection(self, auto_response: AutoResponse, context: Dict[str, Any] = None) -> str:
        """
        Handle repository selection prompts with context awareness.
        
        Args:
            auto_response: The initial auto response
            context: Additional context including repository information
            
        Returns:
            Repository selection response
        """
        # Check if we have a specific repository URL in context
        current_repo_url = None
        
        # Try multiple sources for repository URL
        if context and context.get("repository_url"):
            current_repo_url = context["repository_url"]
        elif self.repository_context.get("repository_url"):
            current_repo_url = self.repository_context["repository_url"]
        
        if current_repo_url:
            # If asking for repository URL directly, provide it
            if "enter repository url" in auto_response.original_prompt.lower():
                logger.info("Providing repository URL from context", url=current_repo_url)
                return current_repo_url
        
        # For numbered selection, default to first option
        if re.search(r"\(1-\d+\)", auto_response.original_prompt):
            logger.info("Auto-selecting first repository option")
            return "1"
        
        # Default response
        return auto_response.response
    
    def _log_response(self, auto_response: AutoResponse):
        """
        Log the automated response for debugging and monitoring.
        
        Args:
            auto_response: The auto response to log
        """
        log_entry = {
            "timestamp": logger._context.get("timestamp"),
            "prompt": auto_response.original_prompt[:200],  # Truncate long prompts
            "response": auto_response.response,
            "prompt_type": auto_response.prompt_type.value,
            "confidence": auto_response.confidence,
            "reasoning": auto_response.reasoning
        }
        
        self.response_log.append(log_entry)
        
        # Keep only last 100 responses to prevent memory issues
        if len(self.response_log) > 100:
            self.response_log = self.response_log[-100:]
    
    def handle_repository_selection(self, options: List[str], context: Dict[str, Any] = None) -> str:
        """
        Handle repository selection from a list of options.
        
        Args:
            options: List of repository options
            context: Additional context for selection
            
        Returns:
            Selected repository identifier
        """
        if not options:
            logger.warning("No repository options provided")
            return "1"  # Default to first option
        
        # Check if current repository context matches any option
        current_repo_url = (context or {}).get("repository_url") or self.repository_context.get("repository_url")
        
        if current_repo_url:
            # Try to find matching option
            for i, option in enumerate(options):
                if current_repo_url in option or option in current_repo_url:
                    selection = str(i + 1)
                    logger.info("Found matching repository in options", 
                               selection=selection, option=option)
                    return selection
        
        # Default to first option
        logger.info("Using default repository selection", selection="1")
        return "1"
    
    def update_repository_context(self, repository_context: Dict[str, Any]):
        """
        Update the repository context for better context-aware responses.
        
        Args:
            repository_context: New repository context
        """
        self.repository_context.update(repository_context)
        logger.info("Repository context updated", 
                   repository_url=self.repository_context.get("repository_url"))
    
    def get_response_log(self) -> List[Dict[str, Any]]:
        """
        Get the log of automated responses for debugging.
        
        Returns:
            List of logged responses
        """
        return self.response_log.copy()
    
    def clear_response_log(self):
        """Clear the response log."""
        self.response_log.clear()
        logger.info("Response log cleared")
    
    def get_statistics(self) -> Dict[str, Any]:
        """
        Get statistics about automated responses.
        
        Returns:
            Dictionary with response statistics
        """
        if not self.response_log:
            return {"total_responses": 0}
        
        prompt_type_counts = {}
        total_confidence = 0.0
        
        for entry in self.response_log:
            prompt_type = entry["prompt_type"]
            prompt_type_counts[prompt_type] = prompt_type_counts.get(prompt_type, 0) + 1
            total_confidence += entry["confidence"]
        
        return {
            "total_responses": len(self.response_log),
            "average_confidence": total_confidence / len(self.response_log),
            "prompt_type_distribution": prompt_type_counts,
            "most_common_prompt_type": max(prompt_type_counts.items(), key=lambda x: x[1])[0] if prompt_type_counts else None
        }